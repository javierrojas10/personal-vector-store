## ðŸŒ What is a Personal Vector Store (PVS)?

A **PVS** is a proposed standard for representing your **identity, expertise, and communication style** in a **portable format** that can be injected into any LLM conversation as contextual system prompts.

Think of it as your **digital professional identity**: a structured JSON file containing your background, skills, and preferences that gets converted into personalized system prompts for consistent interactions across different LLMs (OpenAI, Anthropic, Google, DeepSeek, etc.).

---

## ðŸŽ¯ Goals

* Define an **interoperable format** for representing personal context as structured JSON
* Enable **consistent personalization** across different LLM providers and models
* Provide **systematic benchmarking** to evaluate response quality and consistency
* Build a **community standard** around portable personal context for AI interactions

---

## ðŸ“¦ PVS Structure

Hereâ€™s an example structure in **JSON**:

```json
{
  "pvs_version": "0.1",
  "owner": {
    "name": "Javier Rojas",
    "role": "Software Engineer & Entrepreneur",
    "location": "Chile"
  },
  "identity": {
    "bio": "Backend engineer with Node.js, AWS, and e-commerce experience.",
    "skills": ["Node.js", "TypeScript", "AWS", "RAG", "PrestaShop"],
    "interests": ["AI Agents", "Startups", "E-commerce automation"]
  },
  "communication_style": {
    "tone": "direct",
    "languages": ["es", "en"],
    "preferences": {
      "answers": "short + rationale",
      "code": "no comments",
      "explanations": "always include the why"
    }
  },
  "embedding": {
    "model": "text-embedding-3-large",
    "vector": [0.123, -0.456, ...]
  }
}
```

---

## ðŸš€ Quick Start

```bash
# 1. Install dependencies
npm install

# 2. Set up your API keys (OpenAI required for embeddings)
cp .env.example .env  # Add OPENAI_API_KEY and other provider keys

# 3. Generate your PVS with embeddings from the example profile
npm run generate

# 4. Run benchmarks to compare baseline vs PVS-enhanced responses
npm run benchmark

# 5. Test with specific models
npm run benchmark -- --models openai:gpt-4o,anthropic:claude-3-5-sonnet-20241022

# 6. Analyze token usage of your system prompts
npm run analyze-tokens

# 7. Try the examples to see PVS in action
npm run example
```

See [docs/usage.md](docs/usage.md) for detailed documentation.

---

## ðŸ§ª Project Structure

```
personal-vector-store/
â”œâ”€â”€ src/                 # Core PVS library
â”‚   â”œâ”€â”€ types.ts        # TypeScript interfaces
â”‚   â”œâ”€â”€ generate_pvs.ts # PVS generator script
â”‚   â”œâ”€â”€ embedding_service.ts
â”‚   â””â”€â”€ adapters/       # LLM adapters
â”œâ”€â”€ examples/           # Usage examples and sample profiles
â”œâ”€â”€ benchmarks/         # Benchmark suite and results
â”œâ”€â”€ docs/              # Documentation
â””â”€â”€ README.md
```

## âœ… Current Status

- âœ… **PVS Generator** â†’ converts JSON profiles into PVS format with embeddings
- âœ… **Multi-Model Support** â†’ OpenAI (GPT-4o, GPT-4o-mini), Anthropic (Claude-3.5), Google (Gemini), DeepSeek
- âœ… **System Prompt Generation** â†’ converts PVS data into structured context prompts
- âœ… **Benchmark Framework** â†’ systematic evaluation of baseline vs PVS-enhanced responses
- âœ… **Token Analysis Tools** â†’ estimate and optimize system prompt token consumption
- âœ… **Enhanced CLI** â†’ model selection, progress tracking, and structured output
- ðŸ”„ **Community Standard** â†’ iterating based on real-world usage and feedback

## âš¡ How PVS Actually Works

**PVS uses embeddings for generation, not injection.** Here's the actual workflow:

1. **JSON Profile** â†’ Your identity, skills, and preferences in structured format
2. **Embedding Generation** â†’ OpenAI creates a vector representation for similarity matching (future use)
3. **System Prompt Creation** â†’ Your PVS data becomes a structured system prompt (~100-300 tokens)
4. **LLM Injection** â†’ The text prompt (not the vector) is sent to any LLM for personalized responses

**The embedding vector is NOT sent to LLMs** - only the human-readable context derived from your PVS data.

```bash
# Analyze your token usage
npm run analyze-tokens
npm run token-demo  # Comprehensive analysis
```

---

## ðŸ“¢ Contributing

* Open issues for feedback or feature requests.
* Submit PRs with implementations in different languages (Python, TypeScript, Go).
* Share evaluation results across models.
* Propose better format style.

---

## ðŸ“„ License

MIT â€” open for community use and improvement.


## ðŸš§ Known Issues & Limitations

- âš ï¸ **Anthropic and other non-OpenAI adapters require thorough testing for benchmarking reliability**
- ðŸ“ **Token estimation accuracy varies across different model providers (most accurate for OpenAI)**
- ðŸ› ï¸ **PVS format is in early development; structure may evolve with community feedback**
- ðŸ§ª **Comprehensive test suite and automated CI/CD pipeline are in development**
- ðŸ“„ **Advanced customization docs (custom adapters, embedding models) need expansion**
- ðŸ”§ **Error handling and retry logic need improvement for production use**


If you encounter other issues, please open an issue or PR!

> **Disclaimer:**  
> Parts of this repository, including code, documentation, and design, were developed and refined with the assistance of advanced AI models, notably Anthropic's Claude 4 Sonnet. While human review and curation have been applied, some content may reflect the style, suggestions, or limitations of AI-generated output.  
>  
> Contributions and feedback from the community are welcome to further improve accuracy, clarity, and quality.

